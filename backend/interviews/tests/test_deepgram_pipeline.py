"""
Test cases for Deepgram STT Pipeline

Tests the new pipeline:
1. Video upload ‚Üí Deepgram transcription ‚Üí Store transcript
2. Interview submit ‚Üí Batch LLM analysis
"""

import os
import tempfile
from django.test import TestCase, override_settings
from django.core.files.uploadedfile import SimpleUploadedFile
from unittest.mock import patch, MagicMock
from interviews.models import Interview, VideoResponse, InterviewQuestion, AIAnalysis
from interviews.type_models import PositionType, QuestionType
from applicants.models import Applicant
from accounts.models import User


class DeepgramPipelineTestCase(TestCase):
    """Test Deepgram STT + Gemini LLM pipeline"""
    
    def setUp(self):
        """Set up test data"""
        # Create user
        self.user = User.objects.create_user(
            username='testapplicant',
            email='test@example.com',
            password='testpass123',
            role='applicant'
        )
        
        # Create applicant
        self.applicant = Applicant.objects.create(
            user=self.user,
            first_name='John',
            last_name='Doe',
            email='john@example.com',
            phone='+639123456789',
            status='new'
        )
        
        # Create position type
        self.position_type = PositionType.objects.create(
            name='Software Engineer',
            code='software_engineer',
            is_active=True
        )
        
        # Create question type
        self.question_type = QuestionType.objects.create(
            name='Technical',
            code='technical',
            is_active=True
        )
        
        # Create questions
        self.questions = []
        for i in range(5):
            question = InterviewQuestion.objects.create(
                question_text=f'Test Question {i+1}?',
                question_type=self.question_type,
                position_type=self.position_type,
                is_active=True,
                order=i
            )
            self.questions.append(question)
        
        # Create interview
        self.interview = Interview.objects.create(
            applicant=self.applicant,
            position_type=self.position_type,
            status='in_progress'
        )
    
    @patch('interviews.deepgram_service.DeepgramTranscriptionService.transcribe_video')
    def test_video_upload_with_deepgram_transcription(self, mock_transcribe):
        """Test that video upload triggers Deepgram transcription immediately"""
        
        # Mock Deepgram response
        mock_transcribe.return_value = {
            'transcript': 'This is my answer to the interview question.',
            'duration': 45.2,
            'confidence': 0.95,
            'word_count': 8,
            'processing_time': 2.3
        }
        
        # Create a dummy video file
        video_content = b'fake video content'
        video_file = SimpleUploadedFile(
            'test_video.webm',
            video_content,
            content_type='video/webm'
        )
        
        # Upload video
        response = self.client.post(
            f'/api/interviews/{self.interview.id}/video-response/',
            {
                'question_id': self.questions[0].id,
                'video_file_path': video_file,
                'duration': '00:00:45'
            },
            format='multipart'
        )
        
        # Assertions
        self.assertEqual(response.status_code, 201)
        self.assertIn('video_response', response.data)
        self.assertTrue(response.data.get('transcript_ready', False))
        
        # Check video response was created with transcript
        video_response = VideoResponse.objects.get(
            interview=self.interview,
            question=self.questions[0]
        )
        self.assertEqual(video_response.transcript, 'This is my answer to the interview question.')
        self.assertEqual(video_response.status, 'uploaded')
        
        # Verify Deepgram was called
        mock_transcribe.assert_called_once()
    
    @patch('interviews.ai_service.AIAnalysisService.batch_analyze_transcripts')
    def test_interview_submit_batch_analysis(self, mock_batch_analyze):
        """Test that interview submission triggers batch LLM analysis"""
        
        # Create 5 video responses with transcripts already stored
        transcripts = [
            'I have 5 years of experience in Python.',
            'My biggest strength is problem solving.',
            'I handled it by breaking down the problem.',
            'I would prioritize based on business impact.',
            'I see myself leading a team of engineers.'
        ]
        
        for i, question in enumerate(self.questions):
            VideoResponse.objects.create(
                interview=self.interview,
                question=question,
                video_file_path=f'videos/test_{i}.webm',
                duration='00:00:45',
                transcript=transcripts[i],  # Already transcribed!
                status='uploaded'
            )
        
        # Mock LLM batch analysis response
        mock_batch_analyze.return_value = [
            {
                'sentiment_score': 85.0,
                'confidence_score': 80.0,
                'speech_clarity_score': 90.0,
                'content_relevance_score': 88.0,
                'overall_score': 85.75,
                'recommendation': 'pass',
                'analysis_summary': 'Strong technical background.'
            }
            for _ in range(5)
        ]
        
        # Submit interview
        response = self.client.post(f'/api/interviews/{self.interview.id}/submit/')
        
        # Assertions
        self.assertEqual(response.status_code, 200)
        self.assertIn('message', response.data)
        
        # Verify batch analyze was called ONCE with all transcripts
        mock_batch_analyze.assert_called_once()
        call_args = mock_batch_analyze.call_args
        transcripts_data = call_args[0][0]
        
        # Should have all 5 transcripts
        self.assertEqual(len(transcripts_data), 5)
        
        # Each should have the transcript already
        for i, data in enumerate(transcripts_data):
            self.assertEqual(data['transcript'], transcripts[i])
    
    @patch('interviews.deepgram_service.DeepgramTranscriptionService.transcribe_video')
    @patch('interviews.ai_service.AIAnalysisService.batch_analyze_transcripts')
    def test_complete_pipeline_flow(self, mock_batch_analyze, mock_transcribe):
        """Test complete flow: Upload 5 videos ‚Üí Submit ‚Üí Get results"""
        
        # Mock Deepgram transcription
        transcripts = [
            'I have 5 years of experience in Python.',
            'My biggest strength is problem solving.',
            'I handled it by breaking down the problem.',
            'I would prioritize based on business impact.',
            'I see myself leading a team of engineers.'
        ]
        
        def mock_transcribe_side_effect(video_path, video_id):
            idx = video_id % 5
            return {
                'transcript': transcripts[idx],
                'duration': 45.0,
                'confidence': 0.95,
                'word_count': len(transcripts[idx].split()),
                'processing_time': 2.5
            }
        
        mock_transcribe.side_effect = mock_transcribe_side_effect
        
        # Mock LLM analysis
        mock_batch_analyze.return_value = [
            {
                'sentiment_score': 85.0 + i,
                'confidence_score': 80.0 + i,
                'speech_clarity_score': 90.0,
                'content_relevance_score': 88.0,
                'overall_score': 85.0 + i,
                'recommendation': 'pass',
                'analysis_summary': f'Analysis for question {i+1}.'
            }
            for i in range(5)
        ]
        
        # Step 1: Upload 5 videos (each gets transcribed by Deepgram)
        for i, question in enumerate(self.questions):
            video_file = SimpleUploadedFile(
                f'test_video_{i}.webm',
                b'fake video content',
                content_type='video/webm'
            )
            
            response = self.client.post(
                f'/api/interviews/{self.interview.id}/video-response/',
                {
                    'question_id': question.id,
                    'video_file_path': video_file,
                    'duration': '00:00:45'
                },
                format='multipart'
            )
            
            self.assertEqual(response.status_code, 201)
        
        # Verify 5 Deepgram calls (one per video)
        self.assertEqual(mock_transcribe.call_count, 5)
        
        # Verify transcripts are stored
        video_responses = VideoResponse.objects.filter(interview=self.interview)
        self.assertEqual(video_responses.count(), 5)
        for vr in video_responses:
            self.assertIsNotNone(vr.transcript)
            self.assertGreater(len(vr.transcript), 0)
        
        # Step 2: Submit interview (triggers batch LLM analysis)
        response = self.client.post(f'/api/interviews/{self.interview.id}/submit/')
        self.assertEqual(response.status_code, 200)
        
        # Verify only 1 LLM call (batch)
        mock_batch_analyze.assert_called_once()
        
        # Verify all analyses were saved
        analyses = AIAnalysis.objects.filter(video_response__interview=self.interview)
        self.assertEqual(analyses.count(), 5)
    
    def test_deepgram_service_initialization(self):
        """Test that Deepgram service initializes correctly"""
        from interviews.deepgram_service import get_deepgram_service
        
        service = get_deepgram_service()
        self.assertIsNotNone(service)
        self.assertIsNotNone(service.client)
    
    @patch('interviews.deepgram_service.DeepgramTranscriptionService.transcribe_video')
    def test_fallback_transcription_on_submit(self, mock_transcribe):
        """Test that missing transcripts are transcribed on submit (fallback)"""
        
        # Create 5 video responses WITHOUT transcripts (simulating failed upload transcription)
        for i, question in enumerate(self.questions):
            VideoResponse.objects.create(
                interview=self.interview,
                question=question,
                video_file_path=f'videos/test_{i}.webm',
                duration='00:00:45',
                transcript='',  # Empty transcript!
                status='uploaded'
            )
        
        # Mock Deepgram for fallback transcription
        mock_transcribe.return_value = {
            'transcript': 'Fallback transcription.',
            'duration': 45.0,
            'confidence': 0.90,
            'word_count': 2,
            'processing_time': 3.0
        }
        
        # Mock LLM analysis
        with patch('interviews.ai_service.AIAnalysisService.batch_analyze_transcripts') as mock_analyze:
            mock_analyze.return_value = [
                {
                    'sentiment_score': 70.0,
                    'confidence_score': 70.0,
                    'speech_clarity_score': 70.0,
                    'content_relevance_score': 70.0,
                    'overall_score': 70.0,
                    'recommendation': 'review',
                    'analysis_summary': 'Analyzed.'
                }
                for _ in range(5)
            ]
            
            # Submit interview
            response = self.client.post(f'/api/interviews/{self.interview.id}/submit/')
            self.assertEqual(response.status_code, 200)
        
        # Verify fallback transcription was called for all 5 videos
        self.assertEqual(mock_transcribe.call_count, 5)
        
        # Verify transcripts were stored
        for vr in VideoResponse.objects.filter(interview=self.interview):
            self.assertIsNotNone(vr.transcript)
            self.assertGreater(len(vr.transcript), 0)
    
    def test_cost_comparison(self):
        """Test that demonstrates cost savings"""
        
        # OLD PIPELINE: 10 API calls (5 transcribe + 5 analyze)
        old_gemini_calls = 10
        old_cost_per_call = 0.05  # Approximate
        old_total_cost = old_gemini_calls * old_cost_per_call
        
        # NEW PIPELINE: 5 Deepgram calls + 1 Gemini call
        new_deepgram_calls = 5
        new_gemini_calls = 1
        new_deepgram_cost = new_deepgram_calls * 0.0043  # $0.0043 per minute
        new_gemini_cost = new_gemini_calls * 0.025  # Batch analysis
        new_total_cost = new_deepgram_cost + new_gemini_cost
        
        # Calculate savings
        savings = old_total_cost - new_total_cost
        savings_percentage = (savings / old_total_cost) * 100
        
        print(f"\nüìä Cost Comparison:")
        print(f"Old Pipeline: ${old_total_cost:.2f} (10 Gemini calls)")
        print(f"New Pipeline: ${new_total_cost:.2f} (5 Deepgram + 1 Gemini)")
        print(f"Savings: ${savings:.2f} ({savings_percentage:.1f}%)")
        
        # Assertions
        self.assertLess(new_total_cost, old_total_cost)
        self.assertGreater(savings_percentage, 90)  # At least 90% savings


class DeepgramServiceUnitTests(TestCase):
    """Unit tests for Deepgram service functions"""
    
    @patch('interviews.deepgram_service.DeepgramClient')
    def test_service_initialization(self, mock_client):
        """Test Deepgram service initializes with API key"""
        from interviews.deepgram_service import DeepgramTranscriptionService
        
        with override_settings(DEEPGRAM_API_KEY='test_api_key'):
            service = DeepgramTranscriptionService()
            self.assertIsNotNone(service)
    
    def test_service_requires_api_key(self):
        """Test that service fails without API key"""
        from interviews.deepgram_service import DeepgramTranscriptionService
        
        with override_settings(DEEPGRAM_API_KEY=''):
            with self.assertRaises(ValueError):
                DeepgramTranscriptionService()
    
    @patch('interviews.deepgram_service.ffmpeg')
    def test_audio_extraction(self, mock_ffmpeg):
        """Test audio extraction from video"""
        from interviews.deepgram_service import get_deepgram_service
        
        # Mock ffmpeg operations
        mock_stream = MagicMock()
        mock_ffmpeg.input.return_value = mock_stream
        mock_ffmpeg.output.return_value = mock_stream
        mock_ffmpeg.run.return_value = None
        
        service = get_deepgram_service()
        
        # This will be tested in integration tests
        # Unit test just verifies the service exists
        self.assertIsNotNone(service)


class PerformanceTests(TestCase):
    """Performance comparison tests"""
    
    def test_processing_time_comparison(self):
        """Compare processing times between old and new pipeline"""
        
        # OLD PIPELINE: 45s per video √ó 5 = 225s
        old_time_per_video = 45
        old_total_time = old_time_per_video * 5
        
        # NEW PIPELINE: 3s per video √ó 5 + 8s batch = 23s
        new_time_per_video = 3
        new_batch_analysis_time = 8
        new_total_time = (new_time_per_video * 5) + new_batch_analysis_time
        
        # Calculate improvement
        time_saved = old_total_time - new_total_time
        speed_improvement = old_total_time / new_total_time
        
        print(f"\n‚è±Ô∏è  Performance Comparison:")
        print(f"Old Pipeline: {old_total_time}s")
        print(f"New Pipeline: {new_total_time}s")
        print(f"Time Saved: {time_saved}s")
        print(f"Speed Improvement: {speed_improvement:.1f}x faster")
        
        # Assertions
        self.assertLess(new_total_time, old_total_time)
        self.assertGreater(speed_improvement, 9)  # At least 9x faster
